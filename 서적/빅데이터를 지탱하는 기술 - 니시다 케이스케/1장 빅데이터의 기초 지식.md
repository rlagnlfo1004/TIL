# 1-1 빅데이터의 정착


**빅데이터 취급의 여러움** 존재

1. **‘데이터의 분석 방법을 모른다.’** 
데이터가 있어도 이를 통해 가치를 창조하지 못한다면, 의미가 없는 것이다.
2. **‘데이터 처리에 수고와 시간이 걸린다.’** 
지식은 있더라도, 시간과 자원이 많이 소비 된다면, 할 수 있는 것은 한정된다.

이 2가지 어려움 중 이 책에서는 2번째 문제에 대해서만 이야기한다. 즉, ‘어떻게 효율적으로 실행할 것인가?’ 에 대한 이야기를 한다.
<br><br>

### 빅데이터 기술의 요구 - Hadoop, NoSQL

이러한 빅데이터의 취급하기 어려운 점을 극복하기 위해 등장한 빅데이터 기술로는 Hadoop과 NoSQL이 대표적이다. 웹 서버 등에서 생성된 데이터는 처음에는 RDB와 NoSQL 등의 텍스트 데이터에 저장된다. 그 후 모든 데이터가 Hadoop으로 모이고, 거기서 대규모 데이터 처리가 실행된다.
<br><br>

### Hadoop

- **다수의 컴퓨터에서 대량의 데이터 처리하기 위한 시스템**이다.
- 방대한 데이터를 저장해둘 스토리지와 데이터를 순차적으로 처리하기 위해서는 수백, 수천 대 단위의 컴퓨터가 이용되어야 하는데, 이를 관리하는 것이 Hadoop이라는 프레임워크이다.
- 구글에서 개발된 분산 처리 프레임워크인 MapReduce를 참고하여 제작되었다.
- SQL과 같은 쿼리 언어를 Hadoop에서 실행하기 위한 소프트웨어로 Hive가 개발되었다. Hive의 도입으로 프로그래밍 없이 데이터를 집계할 수 있게 함으로써 많은 사람이 사용할 수 있게 되었다.

### NoSQL 데이터베이스

- RDB의 제약을 제거하는 것을 목표로 한 데이터베이스의 총칭이다.
- 즉, NoSQL은 초고용량 데이터 처리 등 성능에 특화된 목적을 위해 비관계형 데이터 저장소에 비구조적인 데이터를 저장하기 위한 분산 저장 시스템이다.
- 다수의 키와 값을 관련지어 저장하는 **key-value store**, JSON과 같은 복잡한 데이터 구조를 저장하는 **document store**, 여러 키를 사용하여 높은 확장성을 제공하는 **wide-column store** 등이 대표적이다.
- RDB보다 **고속의 읽기, 쓰기가 가능하고 분산 처리**에 뛰어나다는 특징이 있다.
<br><br>

Hadoop은 모여진 데이터를 나중에 집계하는 것이 목적이며, NoSQL은 애플리케이션에서 온라인으로 접속하는 데이터베이스이다. 이 둘을 조합함으로써, NoSQL 데이터베이스에 기록하고, Hadoop으로 분산 처리하는 흐름이 정학하게 되었고, 이를 통해 현실적인 비용으로도, 방대한 규모로 계속 증가하는 데이터를 처리할 수 있게 되었다.
<br><br>

### Hadoop에 의한 데이터 웨어하우스의 증가

분산 시스템의 발전에 따라, 대량의 데이터를 보존 및 집계하기 위해 **Hadoop과 Hive**를 사용하게 되었다. 그 결과 Hadoop의 도입을 기술적으로 지원하는 비즈니스가 성립하게 되었다. 그리고 그때 사용하게 된 키워드가 바로 **'빅데이터'**다.

- **가속도적으로 늘어나는 데이터의 처리는 확정성이 뛰어난 Hadoop이 담당**
- **비교적 작은 데이터, 또는 중요한 데이터만을 데이터 웨어하우스에 저장**

이를 통해 데이터 웨어하우스의 부하를 줄일 수 있게 되었다.

<img width="896" height="496" alt="Image" src="https://github.com/user-attachments/assets/c2cdb563-061b-4809-906e-61a3715d7a2e" />

출처 : 빅데이터를 지탱하는 기술 - 니시다 케이스케

<br><br><br><br>

# 1-2 빅데이터 시대의 데이터 분석 기반

빅데이터 기술이 기존의 데이터 웨어하우스와 다른 점은 다수의 분산 시스템을 조합하여 확장성이 뛰어난 데이터 처리 구조를 만든다는 점이다. 이 책에서 다루는 ‘빅데이터 기술’이란 **분산 시스템을 활용하면서 데이터를 순차적으로 가공**해나가는 일련의 구조다.
<br><br>

### 데이터 파이프라인

데이터 수집을 시작으로, 워크플로 관리까지, 차례대로 전달해 나가는 데이터로 구성된 시스템을 **‘데이터 파이프라인’**이라고 한다.

<img width="882" height="390" alt="Image" src="https://github.com/user-attachments/assets/23ea9afc-044a-48cb-8526-90bd5162e6ee" />

출처 : 빅데이터를 지탱하는 기술 - 니시다 케이스케

### 1. 데이터 수집

데이터 전송(data transfer)의 방법은 크게 두 가지가 있다.

- **벌크(bulk) 형** : 이미 어딘가에 존재하는 데이터를 정리해 추출하는 방법으로, 데이터베이스와 파일 서버 등에서 정기적으로 데이터를 수집하는 데에 사용한다.
- **스트리밍(streaming) 형** : 차례차례로 생성되는 데이터를 끊임없이 계속해서 보내는 방법으로 모바일 애플리케이션과 임베디드 장비 등에서 널리 데이터를 수집하는 데 사용된다.

### 2. 스트림 처리와 배치 처리

- **스트림 처리(stream processing)** : 데이터를 실시간으로 처리하는 것, 장기적인 데이터 분석에는 적합하지 않은 문제가 있다.
- **배치 처리(batch processing)** : 어느 정도 정리된 데이터를 효율적으로 가공하는 것으로, 장기적인 데이터 분석을 목적으로 대량의 데이터를 저장하고 처리하는 데 적합하다.

### 3. 분산 스토리지

수집된 데이터는 **분산 스토리지(distribute storage)**에 저장된다. 데이터를 저장하는 방법에는 몇가지 선택이 있다.

- **객체 스토리지** : 한 덩어리로 모인 데이터에 이름을 부여해서 파일로 저장한다.
- **NoSQL 데이터베이스** : 애플리케이션에서 많은 데이터를 읽고 쓰는 데에 있어서 성능이 우수하다.

### 4. 분산 데이터 처리

**분산 스토리지**에 저장된 데이터를 처리하는 데는 **분산 데이터 처리의 프레임워크**가 필요하다. MapReduce가 사용되어진 것이 바로 이 부분이다. 분산 데이터 처리의 주 역할은 나중에 분석하기 쉽도록 **데이터를 가공해서 그 결과를 외부 데이터베이스에 저장**하는 것이다.

분산 스토리지 상의 빅데이터를 SQL로 집계할 때의 두 가지 방법

- **쿼리 엔진** : Hive, 대화형 쿼리 엔진 사용
- **외부의 데이터 웨어하우스 제품을 이용** : **ETL 프로세스**
    1. **분산 스토리지에서 데이터 추출(Extract)**
    2. **가공(Transfrom)**
    3. **데이터 웨어하우스에 로드(Load)**

### 5. 워크플로 관리

전체 데이터 파이프라인의 동작을 관리하기 위해서 ‘워크플로 관리’ 기술을 사용한다. 데이터 파이프라인이 복잡해짐에 따라 그것을 한 곳에서 제어하지 않으면 전체의 움직임을 파악하기가 어렵다. 오류 발생 시의 처리와 다시 처리하기 위한 기능은 필수이다.
<br><br>

---
<br><br>
### **데이터 웨어하우스와 데이터 마트**

**데이터 웨어하우스**는 대량의 데이터를 장기 보존하는 것에 최적화되어 있다. 정리된 데이터를 한 번에 전송하는 것은 뛰어나지만, 소량의 데이터를 자주 쓰고 읽는 데는 적합하지 않다.

- 데이터 소스(data source) : 업무 시스템을 위한 RDB나 로그 등을 저장하는 파일 서버
- ETL 프로세스 : 데이터 소스에 존재하는 raw 데이터를 추출하고 필요에 따라 가공한 후 데이터 웨어하우스에 저장하기까지의 흐름

데이터 웨어하우스는 중요한 데이터 처리에 사용되기 때문에 함부로 사용해 시스템 과부하를 초래하면 안된다. 따라서 데이터 분석과 같은 목적에 사용하는 경우에는 데이터 웨어하우스에서 필요한 데이터만을 추출하여 **데이터 마트(data mart)**를 구축한다. 데이터 마트는 BI 도구와 조합시키는 형태로 데이터를 시각화하는 데에도 사용된다.

데이터 웨어하우스, 데이터 마트 모두 SQL로 데이터를 집계한다. 먼저 테이블 설계를 제대로 정한 후에 데이터를 투입하기에, 데이터 파이프라인에서는, 테이블 설계와 ETL 프로세스가 중요하다.
<br><br>

### 데이터 레이크와 데이터 마트

**데이터 레이크**는 모든 데이터를 원래의 형태로 저장하고, 나중에 필요한 것만을 꺼내서 사용한다. 즉, 미가공의 원시/로우 데이터를 그대로 저장하는 저장소이다. 구체적으로는 임의의 데이터를 저장할 수 있는 **분산 스토리지가 데이터 레이크로 이용**된다. 이를 정리하면,

- 미가공의 원시 데이터 그대로 저장
- 나중에 가공 및 테이블 설계

데이터 레이크는 단순한 스토리지므로 이것만으로 데이터를 가공할 수 없다. 그래서 사용되는 것이 **MapReduce 등의 분산 데이터 처리 기술**이다. 데이터 분석에 필요한 데이터를 가공, 집계하고, 이를 **데이터 마트로 추출**한 후에는 데이터 웨어하우스의 경우처럼 데이터 분석을 진행할 수 있다.
<br><br>

---
<br><br>

### 데이터 수집의 목적

### 1. 데이터 검색

- 대량의 데이터 중에서 조건에 맞는 것을 찾고 싶은 경우
- 필요할 때 신속하게 검색할 수 있어야 하므로 시스템에는 **실시간 데이터 처리나 검색 엔진을 사용하여 키워드를 찾는 기능**이 필요하다.

### 2. 데이터 가공

- 업무 시스템의 일부로서 데이터 처리 결과를 이용하고 싶은 경우
- 이 경우 목적이 명확하기 때문에 필요한 데이터를 계획적으로 모아 데이터 파이프라인을 설계한다.
- 데이터 가공에는 **워크플로 관리를 통한 자동화**가 필수적이다.

### 3. 데이터 시각화

- 데이터를 시각적으로 봄으로써 앞으로의 상황을 예측해 의사 결정에 도움이 되도록 하는 경우
- 고속화를 위해 **데이터 마트**가 필요하다.
<br><br><br><br>

# 1-3 스크립트 언어에 의한 특별 분석과 데이터 프레임

데이터 분석을 하기 위해 우선 데이터를 수집해야한다. 그 과정에서, 원시 데이터 그대로는 BI 도구로 읽을 수 없어 **‘전처리’**가 필요한 데이터도 있다. 이때, 사용하는것이 R과 Python 같은 스크립트 언어이다.
<br><br>

### 데이터 프레임

**‘데이터 프레임’은 표 형식의 데이터를 추상화한 객체**이다. 데이터 프레임을 사용하면 스크립트 언어 안에서 데이터 가공과 집계를 할 수 있다. 즉, JSON 데이터나 텍스트 데이터 등도 한 번 데이터 프레임으로 변환해 버리면, 테이블 형식의 데이터로 처리할 수 있다. 이는 스프레드시트와 다르지 않다.
<br><br>

### **데이터 전처리에 사용할 수 있는 pandas의 함수**

| 이름 | 설명 |
| --- | --- |
| ix | 조건에 일치하는 데이터 검색 |
| drop | 지정한 행(칼럼) 삭제 |
| rename | 인덱스 값(칼럼명) 변경 |
| dropna | 값이 없는 행(칼럼명) 제외 |
| fillna | 값이 없는 셀을 지정한 값으로 치환 |
| apply | 각 칼럼(행)에 함수 적용 |

추가로, pandas의 데이터 프레임은 메모리상에서 전개되기에 스몰 데이터라면, 매우 빠른 처리가 가능하다.
<br><br>

### 시계열 데이터를 대화식으로 집계하기

pandas에는 시계열 데이터를 취급하기 위한 다양한 기능이 있다. 시간을 인덱스로 지정함으로써 시계열 데이터를 분석할 수 있다.
<br><br>

### **SQL 결과를 데이터 프레임으로**

데이터 프레임은 표 형식의 모든 데이터를 손쉽게 다룰 수 있으므로, SQL로 집계한 결과를 스크립트로 처리하고자 할때도 유용하다.

위의 내용들을 정리하자면, '**파이썬'** 등의 스크립트 언어를 사용하면, **'데이터 프레임'**을 사용해서 테이블 형식의 데이터를 처리할 수 있다. 이것은 특히 **'로우 데이터'**를 취급할 기회가 많은 데이터 엔지니어에게 유용하다. 또한, SQL로 집계한 결과를 스크립트로 처리하고자 할 때도 유용하다. 빅데이터 분석도 결국 이와 같은 것을 '어떻게 대규모로 실행할 것인가?'하는 문제이다.
<br><br><br><br>

# 1-4 BI 도구와 모니터링


데이터 탐색에서 중요한 것은 우선 큰 그림을 파악한 후에 점차 세부 사항으로 깊이 들어가는 것이다.
<br><br>

### 모니터링

모니터링은 계획적으로 데이터의 변화를 추적해 나가는 것이다. 데이터는 현재 상황을 파악하기 위한 하나의 도구로 **자신의 다음 행동을 결정하기 위한 재료**로서 데이터를 살펴 볼 수 있다.
<br><br>

### 데이터에 근거한 의사 결정

프로젝트의 현황을 파악하기 위한 숫자로, 업계마다 중요한 지표인 **KPI(Key Peroformance Indicator)**가 자주 이용된다.

ex) 웹 서비스의 KPI

| 약칭 | 정식 명칭 | 의미 |
| --- | --- | --- |
| DAU | Daily Active User | 서비스를 이용한 1일 유저 수 |
| 계속률 | Customer Retention | 서비스를 계속해서 이용하고 있는 유저의 비율 |
| ARPPU | Average Revenue Per Paid User | 유료 고객 1인당 평균 매출 |

**KPI 모니터링**에서 의식하고 싶은 것은 **‘그것이 행동 가능(actionable)한 것인가?’** 이다. 즉, 결과에 따라 자신의 다음 행동이 결정될 지의 여부다. 자신의 행동을 결정할 때 객관적인 데이터를 근거하여 판단하는 것을 **‘데이터 기반(data-driven) 의사 결정’**이라고 한다.
<br><br>

### 모니터링의 기본 전략 및 BI 도구

데이터의 움직임을 **모니터링하기 위한 기본적인 전략은 우선 정기적인 보고를 통해 중요한 변화를 파악**하는 것이다. 그리고 그 원인을 알기 위해 원인이 되는 데이터로 돌아와 **재집계를 반복하며 자세히 살펴보는 것**이다. **BI 도구는** 이를 위한 소프트웨어이고 데이터를 자세히 탐색할 때 그 힘을 발휘한다. BI 도구는 자신이 직접 데이터를 보기 위한 소프트웨어이며, 집계의 단면을 다양하게 전환하면서 원하는 정보를 찾아낼 수 있다.
<br><br>

문제는 항상 이상적인 데이터가 존재할 수 없다는 것이다. 원하는 대로 집계 결과를 얻으려면 ‘시각화하기 쉬운 데이터’를 만들어야 한다. 제대로 설계된 데이터가 없다면, 자신의 생각과 딱 맞는 화면을 만들 수 없다는 점이 BI 도구의 한계이다.
<br><br>

데이터 웨어하우스의 테이블을 설계하고, 보고서 작성에 필요한 데이터를 배치 처리로 집계하며, 그다음에 BI 도구의 화면을 만든다. 이때, 특히 자주 업데이트되는 데이터와 다수의 사람에게 공유되는 데이터 등의 중요성이 높은 것은 차례로 **자동화**해야 한다. 시각화의 바탕이 되는 데이터를 SQL 또는 스크립트를 사용해서 생성하고, 그것을 BI 도구로부터 읽어 들인다. 구체적인 방법으로는 **데이터 마트를 준비하고, 그것을 BI 도루로부터 여는 방법이 있다.** 이는 어떤 테이블이라도 자유롭게 만들 수 있는 장점이 있으며, 데이터 마트의 설치 및 운영에 시간이 걸린다는 단점이 있다.