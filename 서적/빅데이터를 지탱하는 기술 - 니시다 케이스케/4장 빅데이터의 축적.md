# 4-1 벌크 형과 스트리밍 형의 데이터 수집
<br><br>

### 객체 스토리지와 데이터 수집

빅데이터는 대부분의 경우 확장성이 높은 **‘분산 스토리지(distributed storage)’**에 저장된다. 분산 형의 데이터베이스를 사용하기도 하나, 기본은 파일을 저장하기 위한 **‘객체 스토리지(object storage)’**가 사용된다.

(ex. Hadoop의 **‘HDFS’**, AWS의 **‘Amazon S3’**)
<br><br>

<img width="686" height="400" alt="Image" src="https://github.com/user-attachments/assets/0ef2ff63-282c-4e99-9033-f1fccedf6aa2" />

객체 스토리지에서는 다수의 컴퓨터를 사용하여 파일을 여러 디스크에 복사함으로써 데이터의 중복화 및 부하 분산을 실현하고 있다.
<br><br>

### 객체 스토리지의 특징

- 객체 스토리지에서의 파일 읽고/쓰기는 네트워크를 거쳐서 실행된다.
- 데이터는 항상 여러 디스크에 복사된다.
- 데이터 읽고/쓰기를 여러 하드웨어에 분산 처리한다.
<br><br>

### 데이터 수집

수집한 데이터를 가공하여 집계 효율이 좋은 분산 스토리지를 만드는 일련의 프로세스를 **‘데이터 수집(data ingestion)’**이라 한다.

***“수집 → 데이터 구조화 → 분산 스토리지에 장기적 저장”***
<br><br>

이때, 빅데이터는 단지 수집만 해서는 안 되고, 나중에 처리하기 쉽도록 준비해 둘 필요가 있다. 객체 스토리지에서 효율적으로 처리할 수 있는 파일 크기는 대략 1메가바이트 에서 1기가바이트 사이의 범위이다. 너무 작은 데이터는 모아서 기록하고, 너무 큰 데이터는 분할하여 기록하여, 파일 사이즈를 적절한 크기로 유지하는 것이 중요하다.
<br><br>

---
<br><br>

## (1) 벌크 형의 데이터 전송

- 과거에 축적된 대량의 데이터가 이미 있는 경우
- 기존의 데이터 베이스에서 데이터를 추출하고 싶은 경우
<br><br>

### ETL 서버(ETL server)

<img width="856" height="414" alt="Image" src="https://github.com/user-attachments/assets/d0b41602-9f67-459c-aac2-fba74a8a8b50" />
<br><br>

### 데이터 전송의 워크플로

문제가 발생했을 때, 여러번 데이터 전송을 재실행 할 수 있다는 점이 벌크 형의 장점이다. 또한, 과거의 데이터를 빠짐없이 가져오거나 실패한 작업을 재실행 할 것을 고려한다면, 벌크 형 전송을 해야 한다. 이러한 특성으로 벌크형 데이터 전송은 워크플로 관리 도구와 조합시켜 도입한다.

**워크플로 관리 도구** → 정기적인 스케줄 실행 및 오류 통지
<br><br>

---
<br><br>

## (2) 스트리밍 형의 데이터 전송

- 계속해서 전송되어 오는 작은 데이터를 취급하기 위한 데이터 전송
- 지금 바로 생성되어 아직 어디에도 저장되지 않은 데이터는 그 자리에서 바로 전송
- 다수의 클라이언트에서 계속해서 작은 데이터가 전송됨
- **메시지 배송(message delivery)**
<br><br>

> **메시지 배송**
> 
> - **클라이언트(client)** : 메시지가 처음 생성되는 기기
> - **프런트 엔드(frontend)** : 해당 메시지를 먼저 받는 서버
> 
> 프런트 엔드가 받은 메시지는 그대로 메시지 브로커로 전송된다. 분산 스토리지에 데이터를 저장하는 것은 메시지 브로커로부터 그 이후의 역할이다.
>
<br><br><br><br>

# 4-2 [성능x신뢰성] 메시지 배송의 트레이드 오프
<br><br>

### 메시지 브로커

대량의 메시지를 안정적으로 받기 위해서는 빈번한 쓰기에도 견딜 수 있도록 성능이 애무 높고, 필요에 따라 성능을 얼마든지 올릴 수 있는 스토리지가 필요하다. 분산 스토리지가 반드시 그런 성격을 가지고 있다고 할 수 없기에 빅데이터 메시지 배송 시스템에서는 종종 데이터를 일시적으로 축적하는 중간 계층인 **‘메시지 브로커(message broker)’**가 존재한다. 빅데이터를 위한 분산형 메시지 브로커는 오픈소스의 경우 **‘Apache Kafka(아파치 카프카)’**가 있다.
<br><br>

### 푸시 형과 풀 형

<img width="840" height="660" alt="Image" src="https://github.com/user-attachments/assets/2e1ad222-94e3-43b1-b72a-02622b08ee84" />
<br><br>

- **‘푸시(push)’ 형:**
    - 송신 측의 제어로 데이터를 보내는 방식
    - 메시지 브로커에 데이터를 넣는(push) 것을 **‘생상자(producer)’**
    - 푸시 형의 메시지 배송은 모두 메시지 브로커에 집중한다.
- **‘풀(pull)’ 형:**
    - 수신 측의 주도로 데이터를 가져오는 것
    - 메시지 브로커에 데이터를 꺼내오는(pull) 것을 **‘소비자(consumer)’**
    - 일정한 빈도로 꺼낸 데이터를 분산 스토리지에 기록하여 성능 문제를 피한다.
    - 소비자는 메시지 브로커로부터 일정한 간격으로 적당히 모아진 데이터를 분산 스토리지에 기록한다.
    - 짧은 간격(ex. 1초)으로 차례대로 데이터를 꺼내서 처리하는 것이 **‘스트림 처리(steam processing)’**
<br><br>

메시지 브로커는 데이터의 쓰기 속도를 조정하기 위한 완충 부분으로, 푸시 형에서 풀 형으로 메시지 배송의 타이밍을 변환한다. 메시지 브로커는 높은 빈도로 데이터를 쓰는 것에 최적화 되어있다. 여러 대의 노드에 부하 분산함으로써 성능을 끌어 올릴 수 있는 뛰어난 확장성을 구현하고 있다.
<br><br>

### 메시지 라우팅

**‘메시지 라우팅(message routing)’ :** 메시지 브로커에 써넣은 데이터는 복수의 다른 소비자에서 읽을 수 있다. 이를 통해 메시지가 복사되어 데이터를 여러 경로로 분기시킬 수 있다. 
<br><br>

---
<br><br>

### 신뢰성 문제와 해결 방식

### 1. at most once

- 메시지는 한번만 전송
- 결손 발생 가능
<br><br>

### 2. exactly once

네트워크 상에서 분단된 두 개의 노드가 있는 경우에 양쪽의 통신 내용을 보장하기 위해 그 사이에 → **‘코디네이터(coordinator)’** 존재
<br><br>

- **문제점 1. 분산 시스템에서 코디네이터가 항상 존재 X :** 코디네이터 부재의 경우 어떻게 할 것인가? → **합의**를 해야한다.
- **문제점 2. 성능상의 문제 :** 코디네이터의 판단만 따르면, 시간이 너무 소요된다.
<br><br>

### 3. at least once

- 중복 제거는 사용자에게 맡긴다.
- **메시지가 재전송**
- **중복 가능**
<br><br>

---
<br><br>

### 중복 제거는 높은 비용의 오퍼레이션이다.

- TCP 에서는 메시지에 시퀀스 번호를 붙인다.
- 분산 시스템에서는 시퀀스 번호 사용 X
- 모든 메시지에 일련의 번호를 넣으면 어딘가의 한 부분에서 처리를 집중시켜야 한다. → 성능 향상이 힘들다.
<br><br>

### **해결 방법 1 . 오프셋을 이용한 중복 제거**

- 전송해야 할 데이터에 파일명 등의 이름을 부여해 그것을 작은 메시지에 실어서 배송한다.
- 각 메시지에는 파일 안의 시작위치(오프셋)를 덧붙인다.
- 벌크 형의 데이터 전송과 같이 데이터양이 고정된 경우에 작동한다.
<br><br>

### 해결 방법 2. 고유 ID에 의한 중복 제거

- 스트리밍 형의 메시지 배송에서 사용
- **‘UUID(Universally Unique IDentifier)’**
- 결국 어떻게 ID를 관리? 가 문제이다. → 현실적으로 최근에 받은 ID만을 기억한다.
<br><br>

### (결론) 종단간(End to End)의 신뢰성

신뢰성이 높은 메시지 배송을 실현하려면, 중간 경로를 모두 **‘at least once’**로 통일한 후 클라이언트 상에서 모든 메시지에 **고유 ID**를 포함하도록 하고 경로의 말단에서 **중복 제거**를 실행해야 한다.
<br><br>

### 고유 ID를 사용한 중복 제거의 방법

1. **분산 스토리지로 NoSQL 데이터베이스 이용 :** 특성상 데이터를 쓸 때 고유 ID를 지정하게 되어있기에, 동일한 ID의 데이터는 덮어쓴다.
2. **SQL로 중복 제거 :** 보내온 데이터는 일단 그대로 객체 스토리지 등에 저장하고, 나중에 읽어 들이는 단계에서 중복을 제거한다. 대규모 데이터 처리 능력이 필요하기에, 메모리에서의 실행은 거의 불가능 하며, Hive 같은 배치형 쿼리 엔진에서 실행한다.
<br><br>

---
<br><br>

### 데이터 수집의 파이프라인

<img width="816" height="450" alt="Image" src="https://github.com/user-attachments/assets/7f98cf0e-a612-4cd2-b722-331913ccd48e" />

<br><br><br><br>

# 4-3 시계열 데이터의 최적화
<br><br>

스트리밍 형 메시지 배송에서는 메시지가 도착할 때까지의 시간이 지연에 대해 다룬다.

- **이벤트 시간(event time) :** 클라이언트 상에서 메시지가 생성된 시간
- **프로세스 시간(process time) :** 서버가 처리하는 시간
<br><br>

데이터 분석의 대상은 **‘이벤트 시간’**이지만, 분산 스토리지에 데이터를 넣는 단계에서는 **‘프로세스 시간’**을 사용한다. 즉 프로세스 시간을 사용하여 파일을 작성한다. 

따라서, 과거의 특정 일에 발생한 이벤트를 집계하고 싶다면, 다수의 파일을 모두 검색하는 쿼리인 **‘풀 스캔(full scan)’**을 해야한다. 이는 시스템의 부하를 크게 높이는 요인이다.
<br><br>

---
<br><br>

## 이벤트 시간에 의한 집계 효율화

이벤트 시간 취급을 효율화 하기 위해 데이터를 정렬해보자
<br><br>

### 방법 1. 시계열 인덱스(time-series index)

시계열 인덱스를 사용하면, 매우 짧은 범위의 특정 시간에 맞춘 데이터 집계를 빠르게 실행할 수 있다. 하지만, 장시간에 걸쳐서 대량의 데이터를 집계하는 경우에는 분산 데이터베이스가 그다지 효율적이지 않다. 결국 집계 효율이 높은 열 지향 스토리지를 만들어야 한다.
<br><br>

### 방법 2. 조건절 푸시다운

<img width="882" height="430" alt="Image" src="https://github.com/user-attachments/assets/f2342628-f77e-43a0-990e-c6f814707c94" />


매일 한 번씩 새로 도착한 데이터를 배치 처리로 변환하는 경우에, 이벤트 시간으로 데이터를 **정렬**한 후에 열 지향 스토리지로 변환한다. 
<br><br>

<img width="818" height="516" alt="Image" src="https://github.com/user-attachments/assets/9d3101c5-c382-4573-8334-6d0b00d9f263" />



열 지향 스토리지는 ‘칼럼 단위의 통계 정보’를 이용하여 최적화가 이루어진다. 예를 들어, 시간이면 각 칼럼의 최솟값과 최댓값 등이 모든 파일에 메타 정보로 저장되어 있어, 그런 정보를 참고하여 어떤 파일의 어떤 부분에 원하는 데이터가 포함되어 있는지 알 수 있다. 이러한 통계를 이용하여 필요 최소한의 데이터만을 읽도록 하는 최적화를 **‘조건절 푸시 다운(predicate pushdown)’**이라 한다.
<br><br>

---
<br><br>

### 이벤트 시간에 의한 분할

<img width="908" height="520" alt="Image" src="https://github.com/user-attachments/assets/33b673b8-2be8-4836-96f4-d5d16bdf5dd7" />

**이벤트 시간**을 사용하여 테이블을 물리적으로 나누는, **테이블 파티셔닝** 해보자. 시간을 이용하여 분할된 테이블을 **‘시계열 테이블(time-series table)’** 이라 한다.
<br><br>

**문제점**

시계열 테이블을 구성하는 각 파티션에는 매일 조금씩 데이터가 추가된다. 결과적으로, 분산 스토리지에는 대량의 작은 파일이 만들어지게 되고, 점차 쿼리의 성능이 악화된다.
<br><br>

### 데이터 마트를 이벤트 시간으로 정렬하기

<img width="920" height="506" alt="Image" src="https://github.com/user-attachments/assets/acda14a7-4c25-40ea-86ab-59cdf9e9e098" />

- **데이터 수집 단계 :** 이벤트 시간을 따지지 않고, **프로세스 시간**만을 사용하여 데이터 저장
- **데이터 마트 :** 데이터 마트를 만드는 단계에서 **이벤트 시간에 의한 정렬**을 함께 진행한다.
<br><br>

이를 통해 파일이 조각나는 일도 없고, 항상 최적의 데이터 마트를 유지할 수 있다.
<br><br><br><br>


# 4-4 비구조화 데이터의 분산 스토리지

## 객체 스토리지

### **장점**

- 임의의 파일을 저장할 수 있다.
- 확장성이 있다.
- 데이터를 구조화 하지 않고도 저장할 수 있다.

### **단점**

- 객체 스토리지 상의 파일은 교체하기 어렵다.
- 객체 스토리지에 저장된 데이터를 집계할 수 있게 되기까지는 시간이 걸린다.
<br><br>

---
<br><br>

## NoSQL 데이터베이스
<br><br>

### 1. 분산 KVS

**‘분산 KVS(distributed Key-Value Store)’**는 모든 데이터를 키값 쌍으로 저장한다.

- 모든 데이터에 고유의 키를 지정하고, 그것을 부하 분산을 위해 이용한다.
- 키 값이 정해지면, 그 값을 클러스터 내의 어느 노드에 배치할 것인지 결정한다.
- 노드 간에 부하를 균등하게 분산
- 노드를 증감 → 클러스터의 성능 변경

<img width="1060" height="504" alt="Image" src="https://github.com/user-attachments/assets/891f527c-23af-4c3b-9073-f5c7409d2ff7" />
<br><br>

### Amazon DynamoDB

- 분산형 NoSQL 데이터베이스
- 하나 또는 두 개의 키에 연결하는 형태로 임의의 스키마리스 데이터 저장 가능
- 도큐먼트 스토어로 사용가능하다.
- P2P형의 분산 아키텍처
- 사용자의 요청 수에 따라 노드 증감
<br><br><br><br>


### 2. 와이드 칼럼 스토어

분산 KVS를 발전시켜 2개 이상의 임의의 키에 데이터를 저장할 수 있도록 한 것이 **‘와이드 칼럼 스토어(wide-column store)’**다.

- 내부적으로 행 키와 칼럼 명의 조합에 대해 값을 저장한다.
- 즉, 내부적으로 키마다 칼럼과 값이 저장되는 중첩의 데이터 구조이다.
- 칼럼을 얼마든지 추가할 수 있다.
<img width="912" height="488" alt="Image" src="https://github.com/user-attachments/assets/3e19024e-822b-4ab3-9b6d-eb05844b2783" />
<br><br>

### Apache Cassandra

- 와이드 칼럼 스토어
- ‘CQL’ 쿼리 언어 구현
- 먼저 테이블의 스키마를 결정할 필요가 있기에, 구조화 데이터만을 취급할 수 있다.
- INSERT INTO는 ‘추가 또는 갱신’(이른바 “upsert”)으로 동작해 동일한 키를 가진 레코드가 존재하면 덮어쓴다.
- P2P 형의 분산 아키텍처
- 지정한 키에 의해 결정한 노드에 해당 키와 관련된 모든 값을 저장한다.
- 사용자 ID를 키로 사용하는 경우, 그 사용자에 대한 기록은 하나의 노드에 모이고 그 노드 안에서 쿼리가 실행되기에, 다수의 독립적인 키가 있는 경우, 처리를 잘 분산할 수 있다.
- 복합 키(compound key)
- 집계를 위해서는 분산된 모든 노드에서 데이터를 모아야 하기에, 데이터를 집계하는 데는 적합하지 않다.
- 따라서, 데이터 분석을 위해서는, Hive와 Presto, Spark 등의 쿼리 엔진을 통해 Cassandra로부터의 로드하여 데이터를 추출해야한다.
<br><br><br><br>


### 3. 도큐먼트 스토어

- 데이터 처리의 유연성을 목적으로 한다.
- JSON처럼 복잡하게 뒤얽힌 스키마리스 데이터를 그대로의 형태로 저장하고 쿼리를 실행할 수 있도록 한다.
- 배열과 연상 배열(맵 형)과 같은 중첩된 데이터 구조에 대해 인덱스를 만들거나 도큐먼트 일부만을 치환하는 식의 쿼리를 쉽게 실행할 수 있다.
- 스키마를 정하지 않고 데이터 처리를 할 수 있다.

### MongoDB

- 오픈 소스의 분산형 도큐먼트 스토어로 각종 프로그래밍 언어를 사용하여 데이터를 읽고 쓸 수 있다.
- 여러 노드에 데이터를 분산할 수 있다.
- 대량의 데이터를 집계하는데는 적합하지 않기에, 쿼리 엔진을 통해 데이터를 추출할 필요가 있다.
<br><br>

---
<br><br>

### 검색 엔진

- 키워드 검색으로 데이터를 검색한다.
- 저장된 데이터를 쿼리로 찾아낸다.
- 특히 텍스트 데이터 밒 스키마리스 데이터를 집계하는데 자주 사용된다.
- 텍스트 데이터를 검색하기 위해 **‘역 색인(inverted index)’**을 만든다. 즉, 텍스트에 포함된 단어를 분해하고, 어떤 단어가 어떤 레코드에 포함되어 있는가 하는 인덱스를 먼저 만들어 둠으로써 검색을 고속화 한다.
- 데이터의 집계에 적합하다.
- 장기적으로 데이터를 축적하기 보다는 실시간 집계 시스템의 일부로 사용된다.
<br><br>

### Elasticsearch

- 오픈 소스의 검색 엔진이다.
- 임의의 JSON 데이터를 저장할 수 있기 때문에, 도큐먼트 스토어와 비슷하지만, 아무것도 지정하지 않으면 모든 필드에 색인이 만들어진다.
- 텍스트 데이터에서는 역 색인이 구축된다.
- 열 지향 스토리지에도 대응하고 있어, 그것만으로도 데이터 집계하기 위한 기반이 된다.