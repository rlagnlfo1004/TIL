# 4-1 벌크 형과 스트리밍 형의 데이터 수집
<br><br>

### 객체 스토리지와 데이터 수집

빅데이터는 대부분의 경우 확장성이 높은 **‘분산 스토리지(distributed storage)’**에 저장된다. 분산 형의 데이터베이스를 사용하기도 하나, 기본은 파일을 저장하기 위한 **‘객체 스토리지(object storage)’**가 사용된다.

(ex. Hadoop의 **‘HDFS’**, AWS의 **‘Amazon S3’**)
<br><br>

<img width="686" height="400" alt="Image" src="https://github.com/user-attachments/assets/0ef2ff63-282c-4e99-9033-f1fccedf6aa2" />

객체 스토리지에서는 다수의 컴퓨터를 사용하여 파일을 여러 디스크에 복사함으로써 데이터의 중복화 및 부하 분산을 실현하고 있다.
<br><br>

### 객체 스토리지의 특징

- 객체 스토리지에서의 파일 읽고/쓰기는 네트워크를 거쳐서 실행된다.
- 데이터는 항상 여러 디스크에 복사된다.
- 데이터 읽고/쓰기를 여러 하드웨어에 분산 처리한다.
<br><br>

### 데이터 수집

수집한 데이터를 가공하여 집계 효율이 좋은 분산 스토리지를 만드는 일련의 프로세스를 **‘데이터 수집(data ingestion)’**이라 한다.

***“수집 → 데이터 구조화 → 분산 스토리지에 장기적 저장”***
<br><br>

이때, 빅데이터는 단지 수집만 해서는 안 되고, 나중에 처리하기 쉽도록 준비해 둘 필요가 있다. 객체 스토리지에서 효율적으로 처리할 수 있는 파일 크기는 대략 1메가바이트 에서 1기가바이트 사이의 범위이다. 너무 작은 데이터는 모아서 기록하고, 너무 큰 데이터는 분할하여 기록하여, 파일 사이즈를 적절한 크기로 유지하는 것이 중요하다.
<br><br>

---
<br><br>

## (1) 벌크 형의 데이터 전송

- 과거에 축적된 대량의 데이터가 이미 있는 경우
- 기존의 데이터 베이스에서 데이터를 추출하고 싶은 경우
<br><br>

### ETL 서버(ETL server)

<img width="856" height="414" alt="Image" src="https://github.com/user-attachments/assets/d0b41602-9f67-459c-aac2-fba74a8a8b50" />
<br><br>

### 데이터 전송의 워크플로

문제가 발생했을 때, 여러번 데이터 전송을 재실행 할 수 있다는 점이 벌크 형의 장점이다. 또한, 과거의 데이터를 빠짐없이 가져오거나 실패한 작업을 재실행 할 것을 고려한다면, 벌크 형 전송을 해야 한다. 이러한 특성으로 벌크형 데이터 전송은 워크플로 관리 도구와 조합시켜 도입한다.

**워크플로 관리 도구** → 정기적인 스케줄 실행 및 오류 통지
<br><br>

---
<br><br>

## (2) 스트리밍 형의 데이터 전송

- 계속해서 전송되어 오는 작은 데이터를 취급하기 위한 데이터 전송
- 지금 바로 생성되어 아직 어디에도 저장되지 않은 데이터는 그 자리에서 바로 전송
- 다수의 클라이언트에서 계속해서 작은 데이터가 전송됨
- **메시지 배송(message delivery)**
<br><br>

> **메시지 배송**
> 
> - **클라이언트(client)** : 메시지가 처음 생성되는 기기
> - **프런트 엔드(frontend)** : 해당 메시지를 먼저 받는 서버
> 
> 프런트 엔드가 받은 메시지는 그대로 메시지 브로커로 전송된다. 분산 스토리지에 데이터를 저장하는 것은 메시지 브로커로부터 그 이후의 역할이다.
>
<br><br><br><br>

# 4-2 [성능x신뢰성] 메시지 배송의 트레이드 오프
<br><br>

### 메시지 브로커

대량의 메시지를 안정적으로 받기 위해서는 빈번한 쓰기에도 견딜 수 있도록 성능이 애무 높고, 필요에 따라 성능을 얼마든지 올릴 수 있는 스토리지가 필요하다. 분산 스토리지가 반드시 그런 성격을 가지고 있다고 할 수 없기에 빅데이터 메시지 배송 시스템에서는 종종 데이터를 일시적으로 축적하는 중간 계층인 **‘메시지 브로커(message broker)’**가 존재한다. 빅데이터를 위한 분산형 메시지 브로커는 오픈소스의 경우 **‘Apache Kafka(아파치 카프카)’**가 있다.
<br><br>

### 푸시 형과 풀 형

<img width="840" height="660" alt="Image" src="https://github.com/user-attachments/assets/2e1ad222-94e3-43b1-b72a-02622b08ee84" />
<br><br>

- **‘푸시(push)’ 형:**
    - 송신 측의 제어로 데이터를 보내는 방식
    - 메시지 브로커에 데이터를 넣는(push) 것을 **‘생상자(producer)’**
    - 푸시 형의 메시지 배송은 모두 메시지 브로커에 집중한다.
- **‘풀(pull)’ 형:**
    - 수신 측의 주도로 데이터를 가져오는 것
    - 메시지 브로커에 데이터를 꺼내오는(pull) 것을 **‘소비자(consumer)’**
    - 일정한 빈도로 꺼낸 데이터를 분산 스토리지에 기록하여 성능 문제를 피한다.
    - 소비자는 메시지 브로커로부터 일정한 간격으로 적당히 모아진 데이터를 분산 스토리지에 기록한다.
    - 짧은 간격(ex. 1초)으로 차례대로 데이터를 꺼내서 처리하는 것이 **‘스트림 처리(steam processing)’**
<br><br>

메시지 브로커는 데이터의 쓰기 속도를 조정하기 위한 완충 부분으로, 푸시 형에서 풀 형으로 메시지 배송의 타이밍을 변환한다. 메시지 브로커는 높은 빈도로 데이터를 쓰는 것에 최적화 되어있다. 여러 대의 노드에 부하 분산함으로써 성능을 끌어 올릴 수 있는 뛰어난 확장성을 구현하고 있다.
<br><br>

### 메시지 라우팅

**‘메시지 라우팅(message routing)’ :** 메시지 브로커에 써넣은 데이터는 복수의 다른 소비자에서 읽을 수 있다. 이를 통해 메시지가 복사되어 데이터를 여러 경로로 분기시킬 수 있다. 
<br><br>

---
<br><br>

### 신뢰성 문제와 해결 방식

### 1. at most once

- 메시지는 한번만 전송
- 결손 발생 가능
<br><br>

### 2. exactly once

네트워크 상에서 분단된 두 개의 노드가 있는 경우에 양쪽의 통신 내용을 보장하기 위해 그 사이에 → **‘코디네이터(coordinator)’** 존재
<br><br>

- **문제점 1. 분산 시스템에서 코디네이터가 항상 존재 X :** 코디네이터 부재의 경우 어떻게 할 것인가? → **합의**를 해야한다.
- **문제점 2. 성능상의 문제 :** 코디네이터의 판단만 따르면, 시간이 너무 소요된다.
<br><br>

### 3. at least once

- 중복 제거는 사용자에게 맡긴다.
- **메시지가 재전송**
- **중복 가능**
<br><br>

---
<br><br>

### 중복 제거는 높은 비용의 오퍼레이션이다.

- TCP 에서는 메시지에 시퀀스 번호를 붙인다.
- 분산 시스템에서는 시퀀스 번호 사용 X
- 모든 메시지에 일련의 번호를 넣으면 어딘가의 한 부분에서 처리를 집중시켜야 한다. → 성능 향상이 힘들다.
<br><br>

### **해결 방법 1 . 오프셋을 이용한 중복 제거**

- 전송해야 할 데이터에 파일명 등의 이름을 부여해 그것을 작은 메시지에 실어서 배송한다.
- 각 메시지에는 파일 안의 시작위치(오프셋)를 덧붙인다.
- 벌크 형의 데이터 전송과 같이 데이터양이 고정된 경우에 작동한다.
<br><br>

### 해결 방법 2. 고유 ID에 의한 중복 제거

- 스트리밍 형의 메시지 배송에서 사용
- **‘UUID(Universally Unique IDentifier)’**
- 결국 어떻게 ID를 관리? 가 문제이다. → 현실적으로 최근에 받은 ID만을 기억한다.
<br><br>

### (결론) 종단간(End to End)의 신뢰성

신뢰성이 높은 메시지 배송을 실현하려면, 중간 경로를 모두 **‘at least once’**로 통일한 후 클라이언트 상에서 모든 메시지에 **고유 ID**를 포함하도록 하고 경로의 말단에서 **중복 제거**를 실행해야 한다.
<br><br>

### 고유 ID를 사용한 중복 제거의 방법

1. **분산 스토리지로 NoSQL 데이터베이스 이용 :** 특성상 데이터를 쓸 때 고유 ID를 지정하게 되어있기에, 동일한 ID의 데이터는 덮어쓴다.
2. **SQL로 중복 제거 :** 보내온 데이터는 일단 그대로 객체 스토리지 등에 저장하고, 나중에 읽어 들이는 단계에서 중복을 제거한다. 대규모 데이터 처리 능력이 필요하기에, 메모리에서의 실행은 거의 불가능 하며, Hive 같은 배치형 쿼리 엔진에서 실행한다.
<br><br>

---
<br><br>

### 데이터 수집의 파이프라인

<img width="816" height="450" alt="Image" src="https://github.com/user-attachments/assets/7f98cf0e-a612-4cd2-b722-331913ccd48e" />

<br><br><br><br>

# 4-3 시계열 데이터의 최적화
<br><br>

스트리밍 형 메시지 배송에서는 메시지가 도착할 때까지의 시간이 지연에 대해 다룬다.

- **이벤트 시간(event time) :** 클라이언트 상에서 메시지가 생성된 시간
- **프로세스 시간(process time) :** 서버가 처리하는 시간
<br><br>

데이터 분석의 대상은 **‘이벤트 시간’**이지만, 분산 스토리지에 데이터를 넣는 단계에서는 **‘프로세스 시간’**을 사용한다. 즉 프로세스 시간을 사용하여 파일을 작성한다. 

따라서, 과거의 특정 일에 발생한 이벤트를 집계하고 싶다면, 다수의 파일을 모두 검색하는 쿼리인 **‘풀 스캔(full scan)’**을 해야한다. 이는 시스템의 부하를 크게 높이는 요인이다.
<br><br>

---
<br><br>

## 이벤트 시간에 의한 집계 효율화

이벤트 시간 취급을 효율화 하기 위해 데이터를 정렬해보자
<br><br>

### 방법 1. 시계열 인덱스(time-series index)

시계열 인덱스를 사용하면, 매우 짧은 범위의 특정 시간에 맞춘 데이터 집계를 빠르게 실행할 수 있다. 하지만, 장시간에 걸쳐서 대량의 데이터를 집계하는 경우에는 분산 데이터베이스가 그다지 효율적이지 않다. 결국 집계 효율이 높은 열 지향 스토리지를 만들어야 한다.
<br><br>

### 방법 2. 조건절 푸시다운

<img width="882" height="430" alt="Image" src="https://github.com/user-attachments/assets/f2342628-f77e-43a0-990e-c6f814707c94" />


매일 한 번씩 새로 도착한 데이터를 배치 처리로 변환하는 경우에, 이벤트 시간으로 데이터를 **정렬**한 후에 열 지향 스토리지로 변환한다. 
<br><br>

<img width="818" height="516" alt="Image" src="https://github.com/user-attachments/assets/9d3101c5-c382-4573-8334-6d0b00d9f263" />

열 지향 스토리지는 ‘칼럼 단위의 통계 정보’를 이용하여 최적화가 이루어진다. 예를 들어, 시간이면 각 칼럼의 최솟값과 최댓값 등이 모든 파일에 메타 정보로 저장되어 있어, 그런 정보를 참고하여 어떤 파일의 어떤 부분에 원하는 데이터가 포함되어 있는지 알 수 있다. 이러한 통계를 이용하여 필요 최소한의 데이터만을 읽도록 하는 최적화를 **‘조건절 푸시 다운(predicate pushdown)’**이라 한다.
<br><br>

---
<br><br>

### 이벤트 시간에 의한 분할

<img width="908" height="520" alt="Image" src="https://github.com/user-attachments/assets/33b673b8-2be8-4836-96f4-d5d16bdf5dd7" />

**이벤트 시간**을 사용하여 테이블을 물리적으로 나누는, **테이블 파티셔닝** 해보자. 시간을 이용하여 분할된 테이블을 **‘시계열 테이블(time-series table)’** 이라 한다.
<br><br>

**문제점**

시계열 테이블을 구성하는 각 파티션에는 매일 조금씩 데이터가 추가된다. 결과적으로, 분산 스토리지에는 대량의 작은 파일이 만들어지게 되고, 점차 쿼리의 성능이 악화된다.
<br><br>

### 데이터 마트를 이벤트 시간으로 정렬하기

<img width="920" height="506" alt="Image" src="https://github.com/user-attachments/assets/acda14a7-4c25-40ea-86ab-59cdf9e9e098" />

- **데이터 수집 단계 :** 이벤트 시간을 따지지 않고, **프로세스 시간**만을 사용하여 데이터 저장
- **데이터 마트 :** 데이터 마트를 만드는 단계에서 **이벤트 시간에 의한 정렬**을 함께 진행한다.
<br><br>

이를 통해 파일이 조각나는 일도 없고, 항상 최적의 데이터 마트를 유지할 수 있다.