# 3-1 대규모 분산 처리 프레임워크
<br><br>

## 🔍 구조화 데이터와 비구조화 데이터

- schema가 정의된 데이터 → 구조화 데이터
- schema가 없는 데이터 → 비구조화 데이터
<br><br>

### **“데이터 레이크”**

- **비구조화 데이터 → 분산 스토리지에 저장 → 분산 시스템에서 처리**
- 가공하는 과정에서 스키마를 정의하고, 구조화된 데이터로 변환하여 다른 데이터와 마찬가지로 분석할 수 있다.
<br><br>

### 스키마리스 데이터

- 기본 서식은 있지만, 스키마 정의 X
- CSV, JSON, XML 등의 데이터는 서식은 정해져 있지만, 칼럼 수나 데이터형은 명확하지 않다.
<br><br>

### 데이터 구조화의 파이프라인

- 테이블 형식으로 열 지향 스토리지에 장기 보존
<br>

<img width="1158" height="630" alt="Image" src="https://github.com/user-attachments/assets/4918fb88-e467-4592-b2a7-7e53ff54b5d3" />

1. 각 **데이터 소스**에서 수집된 비구조화 데이터, 또는 스키마리스 데이터는 처음에 **분산 스토리지**에 보존된다.
    - ex. 웹 서버의 로그 파일, 업무용 데이터베이스에서 추출한 마스터 데이터
2. 스키마를 명확하게 한 테이블 형식의 **‘구조화 데이터’**로 변환
    - **분산 시스템의 처리**
    - 일반적으로 구조화 데이터는 데이터의 압축률을 높이기 위해 **열 지향 스토리지**로 저장한다.
    - ex. MPP 데이터베이스로 전송 또는 Hadoop 상에서 열 지향 스토리지 형식으로 변환
    - 시간에 따라 증가하는 데이터 : **팩트 테이블**
    - 그에 따른 부속 데이터 : **디멘전 테이블**
    - 이 단계에서는 테이블 join이 일어나지 않는다.
<br><br>

<aside>

### *“열 지향 스토리지의 작성”*

2번의 과정 즉, **비구조화 데이터를 읽어 들여 열 지향 스토리지로 변환**하는 과정에서는 데이터의 가공 및 압축을 위해 많은 컴퓨터 리소스가 소비된다. 그래서 사용되는 것이 바로 **Hadoop과 Spark 등의 분선 처리 프레임워크**이다.

</aside>
<br><br>

## 🔍 Hadoop

분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체이다.

**YARN**이라 불리는 리소스 관리자 상에서 복수의 분산 애플리케이션이 동작하는 구성으로, 대규모 **분산 시스템을 구축하기 위한 공통의 플랫폼**이다.
<br><br>

### 분산 시스템의 구성요소

- 분산 파일 시스템 : HDFS
- 리소스 관리자 : YARN
- 분산 데이터 처리 : MapReduce, Spark

<img width="1018" height="346" alt="Image" src="https://github.com/user-attachments/assets/8c54c7fb-b7c0-45da-9cb6-a23aec494d56" />
<br><br>

### 분산 데이터의 처리(MapReduce, Tez) & 쿼리 엔진(**Apache Hive)**

- **대량의 비구조화 데이터를 가공 → 구조화 데이터의 생성**
- 장시간의 무거운 배치 처리(한정된 리소스, YARN 상에서 동작)
- Throughput

**쿼리 엔진 : Apache Hive**

- Hive on MR
- Hive on Tez
- Hive on Spark
<br><br>

### 대화형 쿼리 엔진(Apache Impala, Presto)

- 사용할 수 있는 리소스를 최대한 활용하여 쿼리를 실행(YARN과 같은 리소스 관리자 X, 순간 최대 속도를 높이기 위해 모든 오버헤드가 제거)
- SQL의 실행만 특화한 독자적인 분산처리
- MPP 데이터베이스처럼 멀티코어 활용(병렬화, 고속화)
- **Hive를 통해 완성한 구조화 데이터를 대화식으로 집계 (Latency)**
<br><br>

이렇게 다수의 쿼리 엔진을 총칭해 **‘SQL-on-Hadoop’**이라 한다.

→ 분산 스토리지에 저장된 데이터를 신속하게 집계
<br><br><br><br>

## 🔍 Spark (인 메모리 형의 고속 데이터 처리)

- MapReduce를 대체하는 존대
- MapReduce나 Tez의 경우, 처리의 대부분을 **디스크의 읽고 쓰기**에 사용한다.
- 하지만, Spark는 가능한 한 많은 데이터를 메모리상에 올려 디스크에는 아무것도 기록하지 않고, **대량의 메모리를 활용하여 고속화를 실현한다.**
- 중간 데이터를 디스크에 쓰지 않고 메모리에 보존한다.
    
    → 프로그램 실행 중에는 많은 메모리 필요
    
    → 실행 시간의 단축
    
    → 장애 발생시(데이터 손실) : 다시 실행으로 해결
    
<br><br>
Spark에서는 SQL로 쿼리를 실행하기 위한 ‘Spark SQL’과 스트림 처리를 수행하기 위한 ‘Spark Streaming’이라는 기능이 처음부터 포함되어 있기에, 대규모 배치 처리와 SQL에 의한 대화형 쿼리 실행과 실시간 스트림 처리에 까지 널리 사용된다.
<br><br><br><br>

# 3-2 쿼리 엔진


Hive에 의한 구조화 데이터의 생성 과 Presto에 의한 대화식 쿼리에 대해 알아보자.
<br><br>

## 🔍 데이터 마트 구축 파이프라인


Hadoop에 의한 구조화 데이터 작성과 이를 이용한 쿼리의 실행이 어떤 것인지를 알기위해, 쿼리 엔진을 사용하여 데이터 마트를 만드는 파이프라인을 보자. **‘Hive’에 의한 구조화 데이터의 생성** 과 **’Presto’에 의한 대화식 쿼리**에 를 사용한다.
<br><br>

<img width="1044" height="704" alt="Image" src="https://github.com/user-attachments/assets/2e075fae-c1fb-424a-9be2-26b5b2d13be7" />

1. **Hive를 활용한 데이터 구조화 프로세스**
    - 분산 스토리지에 저장된 비구조화/스키마리스 데이터를 **구조화**하고, **열 지향 스토리지 형식**으로 저장한다.
    - 다수의 파일을 가공 → 부하가 크기에 Hive를 사용한다.
2. **비정규화 테이블을 작성하기**
    - 완성한 구조화 데이터를 결합, 집계하고, **비정규화 테이블로 데이터 마트**를 구성한다.
    - 열지향 스토리지를 이용한 쿼리 실행에는 Presto를 사용하여 실행시간을 단축시킨다.
<br><br>

**‘Hive 메타 스토어’:** Hive에서 만든 각 테이블의 정보는 **‘Hive 메타 스토어’**라는 특별한 데이터베이스에 저장된다.
<br><br>

## 1. Hive를 이용한 데이터 구조화 프로세스


### (1 - 1) Hive에 의한 구조화 데이터 작성

**‘외부 테이블’** 정의

- Hive의 외부에 있는 특정 파일을 참고해, 마치 거기에 테이블이 존재하는 것처럼 읽어 들이기 위해 지정한다.
- 데이터를 내부로 전송하지 않고도, 텍스트 파일을 그대로 집계 가능하다.
- 외부 테이블로 지정한 경로에 포함된 모든 CSV 파일이 로드되고, 집계된다.
<br><br>

### (1 - 2) 열 지향 스토리지로의 변환

- 데이터 집계의 고속화(배치형 쿼리 엔진용)
- 새로운 테이블을 생성 하고, 외부에서 읽은 데이터를 모두 저장한다.
- 테이블을 열 지향 스토리지 형식인 ORC 형식으로 변환하는 것이다.

텍스트 데이터를 열 지향 스토리지로 변환함으로써 데이터의 집계가 크게 고속화 된다. 하지만, 이를 작성하는 것은 시간이 걸리는 프로세스이기에, Hive와 같은 배치형 쿼리 엔진에서 실행하는 것이 적합하다.
<br><br><br><br>


## 2. 비정규화 테이블 작성하기


1의 데이터 구조화가 완료 되었다면, 다음은 데이터 마트의 구축이다. 즉, 테이블을 결합 및 집약해서 ‘비정규화 테이블’을 만든다.
<br><br>

### Hive의 쿼리를 개선하는 방법

Hive는 데이터베이스가 아닌 데이터 처리를 위한 배치 처리 구조이기에, 읽어 들이는 데이터의 양을 의식하면서 쿼리를 작성해야 한다.
<br><br>

1. **서브 쿼리 안에서 레코드 수 줄이기**

<img width="1156" height="640" alt="Image" src="https://github.com/user-attachments/assets/52f3d852-4f88-4b58-a4fc-02dec80332bd" />

팩트 페이블(”access_log”)과 디멘전 테이블(”user”)를 결합시에, **서브 쿼리를 통해, 초기에 팩트 테이블을 작게 한다.**
<br><br>

2. **데이터 편향 피하기(분산 시스템의 성능 발휘)**

distict count를 실행하는 것은 다른 처리보다 시간이 오래 걸린다. 중복이 없는 값을 세기 위해서는, 데이터를 한 곳에 모아야하기에, 분산 처리하기 어려워진다. 고속화를 방해하는 다른 하나의 문제는 **‘데이터의 편차’**이다. 

<img width="686" height="445" alt="Image" src="https://github.com/user-attachments/assets/9a13f00e-d3d3-461e-ab2e-f4fa843602fe" />
<br><br>

분산 시스템의 성능을 발휘하기 위해서는 이러한 데이터의 편차를 최대한 없애고, 모든 노드에 데이터가 균등하게 분산되도록 해야한다. 예를 들어 SELECT DISTINCT로 중복을 제거함으로써 부하를 잘 분산하면서 데이터의 양을 줄일 수 있다.
<br><br>

---
<br><br>

### 대화형 쿼리 엔진 Presto로 구조화 데이터 집계하기

Hive는 배치형 쿼리 엔진으로, 대량 출력을 수반하는 대규모 데이터 처리에 적합하지만, 작은 쿼리를 여러번 실행하는 대화형 테이터 처리에는 적합하지 않다. 쿼리 실행의 지연을 감소시키는 것을 목적으로 개발된 것이 ‘대화형 쿼리 엔진’이다.
<br><br>

### Presto의 특징

**플러그인 가능한 스토리지**

- 하나의 쿼리 안에서 여러 데이터 소스에 연결 가능하다.
- 전용 스토리지를 갖고 있지 않으므로, Hive와 마찬가지로 다양한 데이터 소스에서 직접 데이터를 읽어 들인다.
<br><br>

**Presto의 아키텍처**

<img width="942" height="452" alt="Image" src="https://github.com/user-attachments/assets/002e87be-ff91-48ad-9e06-1420bc7ad50d" />

- Presto는 다수의 컴퓨터에서 실행되는 분산 시스템이다.
- 하나의 코디네이터(Coordinator)와 여러 워커(Worker)로 구성된다.
- 쿼리는 Presto CLI 등의 클라이언트 → 코디네이터로 전송된다.
- 코디네이터 : 쿼리를 분석하고, 실행 계획을 수립해 워커에게 처리를 분배한다.
<br><br>

- Presto는 Hive 메타 스토어에 등록된 테이블을 가져올 수 있기에, Hive에서 만든 구조화 데이터를 집계하는 목적에 접합하다.
- Presto가 성능을 발휘하기 위해서는 원래 스토리지가 열 지향 데이터 구조로 되어있어야 한다(특히 ORC 형식).
- 데이터의 로딩 속도를 높이기 위해 Presto 클러스터를 분산 스토리지와 네트워크의 가까운 곳에 설치한 후에 그것을 가능한 한 고속 네트워크에 연결해야 한다.
<br><br><br><br>

**CPU 처리의 최적화**

- Presto는 읽기(열 지향 스토리지)와 코드(SQL 쿼리 → 자바의 바이트 코드)  실행이 병렬로 처리된다.
- 이를 통해 CPU 이용 효율이 높다.
- YARN이나 Mesos와 같은 일반 리소스 관리자를 사용하지 않는다.(Presto 클러스터는 Presto 만을 위해 항상 대기하고 있으며, 쿼리 실행에 컴퓨터의 모든 리소스를 사용한다.)
<br><br>
<br><br>

**인 메모리 처리에 의한 고속화**

- Hive와 달리 Presto는 쿼리 실행 과정에서 디스크에 쓰기를 하지 않는다.
- 따라서 단시간 쿼리 실행에는 대화형 쿼리 엔진을 사용하는 것이 효율적이다.
<br><br><br><br>

**분산 결합(distribute join)**

<img width="1034" height="514" alt="Image" src="https://github.com/user-attachments/as

- Presto의 기본 실행
- 같은 key를 갖는 데이터는 동일 노드에 모인다.
- 노드간의 데이터 전송을 위한 네트워크 통신이 발생한다.(쿼리의 지연 발생)
<br><br>
<br><br>

**브로드캐스트 결합(broadcast join)**

<img width="944" height="450" alt="Image" src="https://github.com/user-attachments/assets/27176ece-93d5-4bca-ba71-19d7118e6285" />

- 한쪽 테이블이 충분히 작을 경우(디멘전 테이블), 브로드캐스트 결합을 통해 처리 속도를 크게 고속화할 수 있다.
- 결합하는 테이블의 모든 데이터가 각 노드에 복사된다.
- 처음에 한번만 복사하면, 팩트 테이블을 재배치 할 필요가 없어서 테이블 결합이 빨라진다.
<br><br>

위와 같은 구조에 의해 Presto에서는 열 지향 스토리지의 집계를 매우 빠르게 실행할 수 있다.
<br><br><br><br>


# 3-3 데이터 마트의 구축

### 팩트 테이블(시계열 데이터 축적하기)

팩트 테이블의 작성에는 2가지 방법이 있다. **추가(append)**와 **치환(replace)**이다.

<img width="864" height="452" alt="Image" src="https://github.com/user-attachments/assets/20ac75b3-6659-4619-8454-a91c5c22081b" />
<br><br>

**추가의 문제점 :**

- 추가에 실패한 것을 알아채지 못하면, 팩트 테이블의 일부에 결손 발생
- 추가를 잘못하여 여러번 실행하면, 팩트 테이블 일부가 중복
- 나중에 팩트 테이블을 다시 만들고 싶은 경우 관리가 복잡

이러한 문제가 일어날 가능성을 줄이기 위해 **‘테이블 파티셔닝(table partitioning)’**
<br><br>

### 테이블 파티셔닝 (물리적 파티션으로 분할)

**하나의 테이블을 여러 물리적인 파티션으로 나눔으로써 파티션 단위로 정리하여, 데이터를 쓰거나 삭제할 수 있다.
(**ex. 1일 1회, 1시간에 1회 새 파티션 생성)
<br><br>

<img width="866" height="538" alt="Image" src="https://github.com/user-attachments/assets/ffef3d4c-bedb-4cdc-96a2-94cb817f36ea" />

- 자주 새 파티션을 만들고, 이를 팩트 테이블에 붙인다.
- 각 파티션은 매변 교체하도록 한다.
- 만약 이미 존재시 덮어쓴다.
<br><br><br><br>

### 데이터 마트의 치환

- 테이블 파티셔닝 → 데이터 웨어하우스 구축
- **데이터 마트를 만드는 경우에는 단순히 팩트 테이블을 치환한다.**
    1. 중간에 데이터 중복 X, 빠뜨릴 가능성 X
    2. 한번의 쿼리 실행으로 치환 가능
    3. 스키마 변경에 유연하게 대응 가능
<br><br>

---
<br><br>

### 집계 테이블(레코드 수 줄이기)

팩트 테이블을 어느 정도 모아서 집계하면 데이터의 양이 크게 준다. 이를 **‘집계 테이블(summary table)’**이라 한다. (ex. 데이터를 1일 단위로 집계 : 일일 집계)
<br><br>
집계 테이블을 작게 하기 위해서는 모든 칼럼의 **카디널리티(각 칼럼이 취하는 범위)**를 줄여야한다.
<br><br>
집계 테이블의 작성은 다차원 모델에서 디멘전을 줄이는(차원을 감소시키는) 효과가 있다.
<br><br>

---
<br><br>

마스터 데이터처럼 업데이트 될 가능성이 있는 테이블에 대해서는 두가지 방안이 있다.

1. **스냅샷 테이블(snapshot table) :** 정기적으로 테이블 통째로 저장
2. **이력 테이블(history table) :** 변경 내용만을 저장
<br><br><br><br>

### 스냅샷 테이블(마스터의 상태를 기록하기)

다음과 같이 **스냅샷(마스터)**과 **트랜잭션**을 결합하여 **집계 테이블**을 생성한다.

<img width="900" height="404" alt="Image" src="https://github.com/user-attachments/assets/61f5c869-ef60-49e7-a475-ebf317615ecf" />
<br><br><br><br>

### 이력 테이블(마스터의 변화 기록하기)

정기적으로 모든 데이터를 스냅샷 하는 것이 아니라, 변경된 데이터만을 증분으로 스냅샷하거나 변경이 있을 때마다 그 내용을 기록한다.
<br><br>

---
<br><br>

### (마지막 단계) **팩트 테이블 + 디멘전 테이블 → 비정규화 테이블**

이때, 디멘전 테이블로는 스냅샷을 사용할 뿐만 아니라, 목적에 따라 각종 중간 테이블이 만들어진다.
<br><br>
예시로, 세션 ID는 그냥 그대로는 카디날리티가 매우 크기에 테이블을 집약해도 작아지지 않을 뿐만 아니라 시각화 하는것도 잘 안되기에, 좀 더 카디널리티가 작은 디멘전을 만들고 결합 후, 시각화에 필요하지 않은 칼럼을 제거하여 시각화 하기 쉽고, 데이터 양이 적은 비정규화 테이블을 만들어 볼 수 있다.

<img width="838" height="448" alt="Image" src="https://github.com/user-attachments/assets/46256997-a9c0-4f03-9eb2-0db70a674f95" />

시각화에 적합한 디멘전만 남기고 집계한다.
<br><br><br><br>

### 데이터 집계의 기본형

1. **팩트 테이블에서 필요한 데이터를 꺼낸다. :** 시간에 의한 검색이나 참고하는 칼럼 수를 줄임으로써 데이터의 로드 속도는 빨라진다.
2. **이를 디멘전 테이블과 결합한다. :** 시각화의 프로세스에서 이용하고 싶은 디멘전만을 추가한다. ****
3. **2의 과정을 반복하여 데이터 마트에 저장할 칼럼을 선택한다. :** 이때, 카디널리티를 작게 하는 것이 중요하다.
4. **마지막으로, 그룹화 하여 측정값을 집계한다. :** 이제 충분히 작은 비정규화 테이블이 만들어 졌다.
5. **그 결과를 데이터 마트로 내보내거나, CSV 파일로 저장한다.**