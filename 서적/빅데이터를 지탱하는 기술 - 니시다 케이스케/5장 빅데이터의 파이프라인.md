# 5-1 워크플로 관리
<br><br>

## 워크플로 관리 도구와 태스크

데이터 파이프라인의 실행 과정에서는 **데이터를 잇달아 이동**하면서 정해진 **처리**를 반복한다. 이때, 실행되는 개별 처리를 **‘태스크(task)’**라고 부른다.
<br><br>
워크플로 관리 도구의 주요 기능은 다음과 같다.

- **태스크를 정기적인 스케줄로 실행하고 그 결과 통지하기**
- **태스크 간의 의존 관계를 정하고, 정해진 순서대로 빠짐없이 실행하기**
- **태스크의 실행 결과를 보관하고, 오류 발생 시에는 재실행 할 수 있도록 하기**
<br><br>
<br><br>

## 오류로부터의 복구 방법 생각하기

워크플로 관리에서는 다음과 같은 것을 생각한다.

- 태스크의 실행 순서
- 오류로부터 어떻게 회복할 것인가라는 계획
<br><br>

### 복구와 플로우의 재실행

오류에는 수많은 가능성이 있으므로, 워크폴로 관리에서는 오류로부터 자동 회복할 수 있다는 점은 고려하지 않는다. 대신에 **수작업에 의한 ‘복귀(recovery)’**를 전제한 태스크를 설계한다. 실패한 태스크는 모두 기록하여, 그것을 나중에 재실행할 수 있도록 해야한다.
<br><br>

### 플로우(flow)

워크플로 관리 도구에 의해 실행되는 일련의 태스크를 **‘플로우(flow)’**라고 부른다. 각 플로우에는 실행시에 고정 **파라미터**가 부여되어 있다. 워크플로 관리 도구는 과거에 실행한 플로우와 그 파라미터를 자동으로 데이터베이스에 기록하게 되어 있다. 그래서 실패한 플로우를 선택하여 재실행하는 것만으로 복귀가 완료된다.
<br><br>

### 백필

실패한 플로우를 복구하는 다른 하나의 수단은 플로우 전체를 처음부터 다시 실행하는 것이다. 이를 위해 이용할 수 있는 것이 **‘백필(backfill)**’기능이다. 백필이란 파라미터에 포함된 일시를 순서대로 바꿔가면서 일정 기간의 플로우를 연속해서 실행하는 구조이다.(파라미터를 바꾸면서 일정 기간의 태스크를 모두 실행한다.)
<br><br><br><br>

## 멱등한 조작으로 태스크를 기술하기

복구에서의 중요한 점은 바로, **‘재실행의 안정성’**이다.
<br><br>

### 원자성 조작

태스크가 시스템에 변경을 가하는 것을 한 번만 할 수 있도록 한다. 트랜잭션 처리에 대응한 데이터베이스라면, 여러 번의 쓰기를 한 번의 트랜잭션으로 실행할 수 있지만, 그렇지 않다면, **쓰기가 필요한 수만큼 태스크**를 나누도록 한다. 이를 **‘원자성 조작(atomic operation)’**이라 하며, **워크플로에 포함된 태스크를 모두 원자성 있는 조작으로 구현함으로써, 재시도 시의 안정성을 높일 수 있다**.
<br><br>

**문제점**

원자성 조작 직후에 문제가 발생하면, 원자성 조작 자체는 성공하고 있음에도 워크플로 관리 도구는 그것을 오류로 여기는 경우가 있다.
<br><br>

### 멱등한 조작

더욱 확실한 것은 **‘동일한 태스크를 여러 번 실행해도 동일한 결과’**가 되도록 하는 것이다. 이것을 **‘멱등한 조작(idempotent operation)’**이라 부른다.

일반적으로 워크플로의 각 태스크는 **‘추가(append)’** 또는 **‘치환(replace)’** 중 하나를 실시한다. **추가**를 반복하면 데이터가 중복되지만, **치환**은 반복해도 결과가 변하지 않으므로 멱등하다고 할 수 있다. **즉, 멱등한 태스크를 만들기 위해서는 태스크에 부여된 파라미터를 잘 이용해 고유의 이름을 생성하고, 여러 번 실행해도 항상 치환이 시행되도록 설계하면 된다.**
<br><br>

### 멱등한 추가

하지만, 과거의 모든 데이터를 치환하면, 멱등하게 되긴 하지만, 부하가 커진다. 또한, 이는 비효율적이며, 성능 저하가 발생할 가능성도 있다. 이에 대한 해결은 **‘테이블 파티셔닝’**이다. 즉, 테이블을 파티션으로 분할하고, **파티션 단위로 치환**한다. (`TRUNCATE`, `INSERT OVERWRITE`)

<img width="824" height="370" alt="Image" src="https://github.com/user-attachments/assets/7c8fd62a-ddcf-425e-afe9-560a73d87483" />
<br><br>

### 태스크 내부에서의 재시도 제어

**‘예기되는 오류’**에 대해서는 워크플로 관리 도구의 재시도에 의존하는 것이 아니라 **태스크 내부에서 명시적으로 대처**해야 한다.(워크플로 관리 도구는 오류의 종류를 구별하지 않는다.) 이런시긍로 태스크의 내부에서 재시도를 제어함으로써, 오류 발생 자체를 회피한다.
<br><br>

- **지수 백오프(exponential backoff)** : 재시도 횟수를 늘림과 동시에, 조금씩 재시도 간격을 넓혀나가기
- **타임 아웃 :** 태스크마다 예상되는 실행 시간과 종료 예정 시간을 설정하여 그 시간이 넘으면 통지해주는 것도 있다. 그 태스크가 만족해야 하는 기준을 정한다는 의미에서 워크플로 관리에서의 **‘SLA(service level Agreement)’**라고 부른다.
<br><br>

### 원자성을 지닌 추가

복잡한 플로우에는 하나의 테이블에 몇 번이고 데이터를 써넣을 때가 있다. 그 경우에는 추가를 반복하는 것이 아니라 **중간 테이블**을 만들어 처리한 후, **마지막에 목적 테이블에 한 번에 추가**하는 것이 안전하다.

- **중간 테이블 : 멱등(치환)**
- **목적 테이블 : INSERT 문으로 단순한 추가**로 멱등하지 않지만, 마지막 쓰기는 1회만 실시되기에 이것은 **원자성을 지닌 조작**이 된다. 따라서, 플로우가 실패한 경우에는 아무것도 쓰이지 않아 실패한 태스크를 재실행하면, 복구가 완료된다.

<img width="672" height="268" alt="Image" src="https://github.com/user-attachments/assets/0c6a91a4-bdc7-4322-88ae-b989a171361c" />
<br><br>

### 워크플로 전체를 멱등으로 하기

- 각 태스크를 멱등으로 하는 것이 이상적이지만, 필수는 아니다.
- 재실행의 안전성을 높이기 위해선는 적어도 각 **플로우가 전체로서 멱등**하게 되도록 구현해야 한다.
<br><br><br><br>

## 태스크 큐

워크플로 관리 도구는 **외부 시스템의 부하 컨트롤**이란 역할 또한 가지고 있다. 이는 **태스크의 크기나 동시 실행 수를 변화**시킴으로써 **자원의 소비량을 조정**하여 **모든 태스크가 원활하게 실행**되도록 한다.
<br><br>
너무 대량의 태스크를 동시 실행하면 서버에 과부하가 걸리므로 어느 정도 제한을 해야 한다. 이때 사용하는 것이 **‘잡 큐(job queue)’**, 또는 **‘태스크 큐(task queue)’**이다. 모든 태스크는 일단 큐에 저장되고, 일정 수의 워커 프로세스가 그것을 순서대로 꺼내면서 병렬화가 실현된다.

<img width="718" height="302" alt="Image" src="https://github.com/user-attachments/assets/02da6b8e-4357-4430-aca5-a0490fd1e7a2" />

이때, 예를들어 태스크에는 날짜와 시간이 파라미터로 건네진다는 점을 활용하여, 각 테스크는 지정된 시간의 데이터를 모아서 처리하도록 구현하면, 태스크가 너무 클 경우에는 나누고, 너무 작을 경우에는 하나로 모음으로써 각 태스크가 적절한 크기가 될 수 있도록 조정한다. 그 다음에 여러 태스크를 동시에 실행하도록 워커의 수를 늘려 두면, 한정된 계산 자원을 낭비하지 않고 활용할 수 있다. 결과적으로 **워크플로 관리 도구에 등록된 태스크는 모두 적당한 크기로 분할된 다수의 태스크가 여러 워커로 부터 호출되고 있는 상태가 된다.**

<img width="772" height="322" alt="Image" src="https://github.com/user-attachments/assets/310b6421-1f7d-4104-b595-a67bdcbf795e" />

이렇게, 데이터 파이프라인 전체가 원활하게 실행되도록 제어하는 것도 워크플로 관리 도구의 역할이다.

<br><br><br><br>

# 5-2 배치 형의 데이터 플로우
<br><br>

## 워크플로와 데이터 플로우

분산 스토리지로의 데이터 전송이 완료되면, 거기서부터는 분산 시스템의 프레임워크를 사용한다. 이때, **다단계의 데이터 처리를 그대로 분산 시스템의 내부에서 실행할 수 있게 되었다. 이제부터는 이것을 '데이터 플로우(data flow)'**라고 지칭하며, 외부 도구에 의존하는 워크플로와는 구분된다.
<br><br>

### MapReduce의 구조

<img width="926" height="462" alt="Image" src="https://github.com/user-attachments/assets/5baad280-e55d-4b2d-89d9-6c2bf7b806c8" />

데이터를 **분산으로 처리**하고 싶기에, 파일을 일정 크기로 나누어 작은 데이터인 **스플릿(split)**을 만든다. 그리고 이들 각각의 처리는 독립적으로, 다수의 컴퓨터에서 분산하여 처리한 후, 분산 처리의 결과를 마지막에 집계한다.

- **Map : 분할된 데이터를 분산 처리**
- **Reduce : 분산 처리의 결과를 모아서 집계**
<br><br>

이렇게 Map과 Reduce를 반복하면서, 목적한 결과를 얻을 때 까지 계속해서 데이터를 변환해 나가는 구조가 MapReduce이다. MapReduce는 Map과 Reduce 하나의 사이클이 끝나지 않으면 다음 처리로 이동하지 않기에, 대기시간이 많이 발행하여, 더 이상 사용되지 않는 프레임워크이다.
<br><br>

### MapReduce를 대신할 새로운 프레임워크 - DAG에 의한 내부 표현

새로운 프레임워크에 공통으로 들어가는 것이 **'DAG(directed acyclic graph)'**라 불리는 데이터 구조다.

- **DAG(Directed Acyclic Graph)**:
    - '방향성 비순환 그래프'라는 의미이다.
    - 노드와 노드가 화살표로 연결된다(방향성).
    - 화살표를 아무리 따라가도 동일 노드로 되돌아오지 않는다(비순환).

**데이터 플로우**에서는 실행해야 할 일련의 **태스크**를 **DAG에 의한 데이터 구조로 표현**한다다. 화살표는 태스크의 실행 순서를 나타낸다. 또한, **데이터 플로우에서는 DAG를 구성하는 각 노드가 모두 동시 병행으로 실행**되어 대기 시간이 사라진다.
<br><br>

요약하자면, **데이터 처리 작업(task)을 DAG라는 구조로 표현함으로써 작업의 순서를 명확히 하고, 안정적이고 효율적인 실행이 가능해진다**는 내용이다.
<br><br>

또한, 데이터 플로우에 더불어 쿼리 엔진에서도 SQL로부터 시스템의 내부적으로 DAG의 데이터 구조가 자동 생성되며, Spark와 같은 데이터 플로우의 프레임워크에서는 프로그래밍 언어를 사용하여 DAG의 데이터 구조를 조립한다.
<br><br>

DAG에 의한 프로그래밍의 특징은 **‘지연 평가(lazy evaluation)’**이다. 프로그램의 각 행은 DAG의 데이터 구조를 조립할 뿐, 바로 무언가를 처리하지 않는다. 즉, **DAG를 구성하지만 즉시 실행을 하지 않는다.**

MapReduce 처럼 Map과 Reduce를 하나씩 실행하는 것이 아니라, 먼저 데이터 파이프라인 전체를 DAG로 조립하고 나서 실행에 옮김으로써 내부 스케줄러가 분산 시스템에 효과적인 실행 계획을 세워주는 것이 데이터 플로우의 장점이다.
<br><br>
<br><br>

## 데이터 플로우와 워크플로를 조합하기

태스크를 정기적으로 실행하거나, 실패한 태스크를 기록하여 복구하는 것은 역시나 **워크플로**의 역할이다. 따라서, 워크플로 관리는 여전히 필요하고, **데이터 플로우의 프로그램도 워크플로의 일부로서 실행되는 하나의 태스크**이다.
<br><br>

데이터 플로우로부터 읽어 들일 데이터는 안정된 분산 스토리지에 배치해야한다.

- 분산 시스템 안에서만 실행되는 데이터 처리 → 데이트 플로우
- 분산 시스템 외부의 데이터를 주고 받을 경우 → 오류 발생의 가능성 → 복구를 고려하여 워크플로 안에서 실행
<br><br>

### 데이터를 읽어들이는 플로우

<img width="766" height="318" alt="Image" src="https://github.com/user-attachments/assets/31aa8f48-9844-4bf3-9997-00a3629b10a6" />

- 외부의 데이터 소스에서 데이터를 읽어 들을 때는 벌크형의 전송 도구로 태스크를 구현한다.(워크플로 관리 도구)
- 위의 데이터의 복사를 완료하면, 데이터 플로우의 역할이다. (안정된 분산 스토리지 사용)
<br><br>

### 데이터를 써서 내보내는 플로우

<img width="770" height="284" alt="Image" src="https://github.com/user-attachments/assets/5255b485-cea0-4a2f-997b-df7d71867013" />

데이터 플로우 안에서 대량의 데이터를 외부에 전송하는 것은 피하는 것이 좋다.  데이터 플로우의 출력은 CSV 파일과 같이 취급하기 쉬운 형식으로 변환하여 분산 스토리지에 써넣는다. 보관을 마치게 되면, 데이터 플로우의 역할은 끝이다. 외부 시스템으로의 데이터 전송은 어떤 오류가 발행할 지 예측할 수 없기에, 워크플로 안에서 전송한다.
<br><br>

### 데이터 웨어하우스의 파이프라인

**데이터 플로우의 역할 : 로드되는 데이터를 만드는 부분**(비구조화 데이터를 가공하여 CSV 파일 등을 만들어 분산 스토리지에 작성한다.)

<img width="830" height="328" alt="Image" src="https://github.com/user-attachments/assets/d62bedbc-9266-47da-803f-d0d4c78b93df" />
<br><br>

### 데이터 마트의 파이프라인

**데이터 플로우의 역할 : 구조화 데이터를 만드는 만드는 부분**(분산 스토리지 상의 데이터를 매일 반복되는 배치로 가공하여 열 지향 스토리지 형식으로 보관한다.)

<img width="834" height="348" alt="Image" src="https://github.com/user-attachments/assets/34c4c990-c7bb-4178-898d-f658b1cc7af9" />
<br><br><br><br>

# 5-3 스트리밍 형의 데이터 플로우

<img width="740" height="316" alt="Image" src="https://github.com/user-attachments/assets/5245434c-8c2d-47d6-a942-03ec3bbed154" />
<br><br>

### **배치 처리**

- 집계 효율을 높이기 위해 **열 지향 스토리지**를 만든다.
- 일정 시간이 소요된다.
- 데이터를 모아서 일정 시간마다 일괄적으로 처리
- 장기적인 데이터 분석에 적합하며, 데이터를 분산 스토리지에 보관하기 때문에 여러 번 재실행 가능
<br><br>

### **스트림 처리**

- 데이터가 도착하는 즉시 거의 동시에 처리
- **'실시간성' :** 이벤트 발생 후 몇 초 안에 결과를 알아야 하는 경우
- 분산 스토리지를 거치지 않고 처리를 계속
- 과거 데이터에 대한 처리는 부적합하며, 처리 내용을 변경해도 이미 처리된 과거 데이터에는 적용되지 않는다.
<br><br>

### 배치 처리와 스트림 처리 통합하기

<img width="804" height="502" alt="Image" src="https://github.com/user-attachments/assets/71051eaf-3f44-42bc-8646-28bb9c05898f" />

- **유한 데이터(Bounded Data):** 배치 처리처럼 데이터의 양이 정해져 있는 데이터
- **무한 데이터(Unbounded Data):** 스트림 처리처럼 끊임없이 생성되는 데이터

두 데이터의 성질은 다르지만, **데이터를 작게 분할해서 DAG(방향성 비순환 그래프)에 흘려 넣어 실행한다**는 점은 동일하다. 따라서 DAG를 사용하는 프레임워크에서는 배치 처리와 스트림 처리를 동일하게 프로그래밍하는 것이 가능해졌다. Spark 스트리밍이 바로 이러한 통합을 구현한 예시이다.
<br><br><br><br>


## 스트림 처리의 결과를 배치 처리로 치환하기
<br><br>

### 스트림 처리의 문제점

1. 틀린 결과를 어떻게 수정할 것인가?
2. 늦게 전송된 데이터의 취급( 메시지 배송에 지연 발생시, 이벤트 시간으로 집계하면 문제 발생)

이에 대한 해결 방안으로 스트림 처리를 속보 값으로 하고, 배치 처리를 확정 값으로 분류하는 방법이다. 즉, 스트림 처리와는 별개로 배치 처리를 실행시켜 후자의 결과가 옳다고 하는 것이다. 스트림 처리의 결과도 배치 처리의 결과가 나올 때까지의 잠정 값으로 이용하는 것이다.